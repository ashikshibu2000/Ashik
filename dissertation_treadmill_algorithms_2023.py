# -*- coding: utf-8 -*-
"""Dissertation Treadmill-Algorithms 2023.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ykGXPxtiI-hP9ddgyvhpwPR8fcg9CUGD

## **Importing Required Libraries**
"""

import pandas as pd
from sklearn.neighbors import KNeighborsClassifier  # for classification
from sklearn.neighbors import KNeighborsRegressor  # for regression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, mean_squared_error,r2_score
from sklearn.tree import DecisionTreeRegressor
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder
from sklearn.ensemble import RandomForestRegressor

"""## **Reading Data from CSV**"""

data = pd.read_csv('/content/treadmillData1.csv')

"""## **Cleaning Data**

**1 . Handling Missing**

Remove rows with missing values
"""

data = data.dropna()

"""Fill missing values with the mean of each column"""

data = data.fillna(data.mean())

"""Interpolate missing values : used for filling missing values based on the values of adjacent rows."""

data = data.interpolate()

"""Custom Filling : Fill missing values with a custom value, e.g., 0


"""

data = data.fillna(0)

"""Forward or Backward Fill :  propagate the last known value forward or the next known value backward to fill missing values."""

# Forward fill (propagate last known value forward)
data = data.ffill()

# Backward fill (propagate next known value backward)
data = data.bfill()

"""Removing Columns with Missing Values:remove columns with a high percentage of missing values if they are not critical to your analysis."""

# Remove columns with missing values (threshold set to 30%)
data = data.dropna(axis=1, thresh=0.7*len(data))

"""Remove duplicate rows"""

data = data.drop_duplicates()

"""## **Renaming columns**"""

# Define the column mapping
column_mapping = {
    'Age(years)': 'Age',
    'Weight(kg)': 'Weight',
    'Height(cm)': 'Height',
    'Humidity(%)': 'Humidity',
    'Speed(km/h)': 'Speed',
    'HR(per min)': 'heart_rate',
    'RR(per minute)': 'respiratory_rate',
    # Add more mappings as needed
}

# Rename the columns based on the mapping
data.rename(columns=column_mapping, inplace=True)

"""## **The k-Nearest Neighbors (k-NN) algorithm**

We are using **'Age','Weight','Height','Humidity', 'respiratory_rate' and 'Speed**' for predicting **'heart_rate'**
"""

names = ['Age','Weight','Height','Humidity','respiratory_rate','Speed']
features = data[names]
target = data['heart_rate']
X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)

"""## **Method 1 : KNN Classification**"""

k = 5  # The number of neighbors to consider (you can choose any suitable value)
knn_classifier = KNeighborsClassifier(n_neighbors=k)
knn_classifier.fit(X_train, y_train)

y_pred = knn_classifier.predict(X_test)
print("prediction using KNN classification : ", y_pred)

accuracy = accuracy_score(y_test, y_pred)
print("Accuracy off KNN classification : ", accuracy)

"""## **Method 2 : KNN Regression**"""

k = 5  # The number of neighbors to consider (you can choose any suitable value)
knn_regressor = KNeighborsRegressor(n_neighbors=k)
knn_regressor.fit(X_train, y_train)

y_pred = knn_regressor.predict(X_test)
print("prediction using KNN Regression : ", y_pred)

mse = mean_squared_error(y_test, y_pred)
print("Mean Squared Error KNN Regression :", mse)

"""### **Appling Decision Tree Algorithm**"""

target_variable = 'heart_rate'
X = data.drop(target_variable, axis=1)
y = data[target_variable]

# Identify numerical and categorical columns
numerical_columns = X.select_dtypes(include=['number']).columns
categorical_columns = X.select_dtypes(include=['object']).columns

# Ensure all categorical columns are strings
X[categorical_columns] = X[categorical_columns].astype(str)

# Create transformers for numerical and categorical columns
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numerical_columns),
        ('cat', OneHotEncoder(drop='first', sparse=False), categorical_columns)
    ])

# Apply transformers to the features
X = preprocessor.fit_transform(X)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize Decision Tree Regressor
dt_regressor = DecisionTreeRegressor(random_state=42)

# Fit the model to the training data
dt_regressor.fit(X_train, y_train)

# Make predictions on the testing set
y_pred = dt_regressor.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f'Mean Squared Error: {mse}')
print(f'R-squared: {r2}')

"""### **Appling Random Forest Algorithm**"""

# Step 1: Feature Selection
selected_features =['Age','Weight','Height','Humidity','respiratory_rate','Speed']
X = data[selected_features]
y = data['heart_rate']

# Encode categorical features using one-hot encoding
X = pd.get_dummies(X, columns=['Age','Weight','Height','Humidity','respiratory_rate','Speed'], drop_first=True)

# Step 2: Data Splitting
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 3: Model Selection
model = RandomForestRegressor(n_estimators=100, random_state=42)

# Step 4: Model Training
model.fit(X_train, y_train)

# Step 5: Model Evaluation
y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
print(f"Mean Squared Error: {mse}")

"""### Draw Histogram of **Heart Rate** by **Speed**"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import seaborn as sns                       #visualisation
import matplotlib.pyplot as plt             #visualisation
# %matplotlib inline
sns.set(color_codes=True)


data = pd.read_csv('/content/treadmillData1.csv')
data = data.fillna(0)
data = data.dropna()
# Define the column mapping
column_mapping = {
    'Age(years)': 'Age',
    'Weight(kg)': 'Weight',
    'Height(cm)': 'Height',
    'Humidity(%)': 'Humidity',
    'Speed(km/h)': 'Speed',
    'HR(per min)': 'heart_rate',
    'RR(per minute)': 'respiratory_rate',
    # Add more mappings as needed
}

# Rename the columns based on the mapping
data.rename(columns=column_mapping, inplace=True)

data.Speed.value_counts().nlargest(40).plot(kind='bar', figsize=(10,5))
plt.title("Heart Rate by Speed")
plt.ylabel('heart_rate')
plt.xlabel('Speed');

"""### **Draw Heat Map of the Dataset**"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import seaborn as sns                       #visualisation
import matplotlib.pyplot as plt             #visualisation
# %matplotlib inline
sns.set(color_codes=True)


data = pd.read_csv('/content/treadmillData1.csv')
data = data.fillna(0)
data = data.dropna()
# Define the column mapping
column_mapping = {
    'Age(years)': 'Age',
    'Weight(kg)': 'Weight',
    'Height(cm)': 'Height',
    'Humidity(%)': 'Humidity',
    'Speed(km/h)': 'Speed',
    'HR(per min)': 'heart_rate',
    'RR(per minute)': 'respiratory_rate',
    # Add more mappings as needed
}

# Rename the columns based on the mapping
data.rename(columns=column_mapping, inplace=True)

plt.figure(figsize=(10,5))
c= data.corr()
sns.heatmap(c,cmap="BrBG",annot=True)
c

"""### Draw Scatterplot of **Heart Rate** by **Speed**"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import seaborn as sns                       #visualisation
import matplotlib.pyplot as plt             #visualisation
# %matplotlib inline
sns.set(color_codes=True)


data = pd.read_csv('/content/treadmillData1.csv')
data = data.fillna(0)
data = data.dropna()
# Define the column mapping
column_mapping = {
    'Age(years)': 'Age',
    'Weight(kg)': 'Weight',
    'Height(cm)': 'Height',
    'Humidity(%)': 'Humidity',
    'Speed(km/h)': 'Speed',
    'HR(per min)': 'heart_rate',
    'RR(per minute)': 'respiratory_rate',
    # Add more mappings as needed
}

# Rename the columns based on the mapping
data.rename(columns=column_mapping, inplace=True)

fig, ax = plt.subplots(figsize=(10,6))
ax.scatter(data['heart_rate'], data['Speed'])
ax.set_xlabel('heart_rate')
ax.set_ylabel('Speed')
plt.show()

"""### **Boxplot of Features**"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler

data = pd.read_csv('/content/treadmillData1.csv')

# Boxplot on numeric columns to find outliers
columns = list(data.select_dtypes(include=['int64','float64']).columns)
num_data = data[columns]
scaler = StandardScaler()
scaled_data = scaler.fit_transform(num_data)
scaled_df = pd.DataFrame(scaled_data, columns=columns)

plt.figure(figsize=(10, 10))
sns.boxplot(data=scaled_df)
plt.xticks(rotation=90)
plt.title('Boxplot of Features')
plt.show()

"""### **Correlation Matrix Heatmap**"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder

data = pd.read_csv('/content/treadmillData1.csv')
# Define the column mapping
column_mapping = {
    'Age(years)': 'Age',
    'Weight(kg)': 'Weight',
    'Height(cm)': 'Height',
    'Humidity(%)': 'Humidity',
    'Speed(km/h)': 'Speed',
    'HR(per min)': 'heart_rate',
    'RR(per minute)': 'respiratory_rate',
    # Add more mappings as needed
}

# Rename the columns based on the mapping
data.rename(columns=column_mapping, inplace=True)

# plotting correlation matrix to find correlation between features
label_encoder = LabelEncoder()

cor_df = pd.concat([scaled_df, data['heart_rate']], axis=1)
cor_df['heart_rate'] = label_encoder.fit_transform(cor_df['heart_rate'])

correlation_matrix = cor_df.corr()


plt.figure(figsize=(10, 10))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")

plt.title('Correlation Matrix Heatmap')
plt.show()

"""### **Elbow Curve**"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
# Usinf elbow method to find optimal k(number of clusters) for kmeans
from sklearn.cluster import KMeans

data = pd.read_csv('/content/treadmillData1.csv')
# Define the column mapping
column_mapping = {
    'Age(years)': 'Age',
    'Weight(kg)': 'Weight',
    'Height(cm)': 'Height',
    'Humidity(%)': 'Humidity',
    'Speed(km/h)': 'Speed',
    'HR(per min)': 'heart_rate',
    'RR(per minute)': 'respiratory_rate',
    'Sex (Female - 1)': 'gender',
    # Add more mappings as needed
}

# Rename the columns based on the mapping
data.rename(columns=column_mapping, inplace=True)

data_cleaned = data[['heart_rate', 'respiratory_rate']].dropna()


inertia = []

for k in range(1, 11):
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(data_cleaned)
    inertia.append(kmeans.inertia_)

# Plotting the elbow curve
plt.figure(figsize=(8, 6))
plt.plot(range(1, 11), inertia, marker='o')
plt.xlabel('Number of Clusters (K)')
plt.ylabel('Inertia (Within-Cluster Sum of Squares)')
plt.title('Elbow Method to Find Optimal Number of Clusters')
plt.show()

"""### **K-means Clustering of heart_rate vs respiratory_rate**"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
# Usinf elbow method to find optimal k(number of clusters) for kmeans
from sklearn.cluster import KMeans

data = pd.read_csv('/content/treadmillData1.csv')
# Define the column mapping
column_mapping = {
    'Age(years)': 'Age',
    'Weight(kg)': 'Weight',
    'Height(cm)': 'Height',
    'Humidity(%)': 'Humidity',
    'Speed(km/h)': 'Speed',
    'HR(per min)': 'heart_rate',
    'RR(per minute)': 'respiratory_rate',
    'Sex (Female - 1)': 'gender',
    # Add more mappings as needed
}

# Rename the columns based on the mapping
data.rename(columns=column_mapping, inplace=True)
data_cleaned = data[['heart_rate', 'respiratory_rate']].dropna()

# Applying Kmeans and plotting the cluster centers and clusters
plt.figure(figsize=(10, 10))

kmeans = KMeans(n_clusters=3, random_state=42)
data_cleaned['Cluster'] = kmeans.fit_predict(data_cleaned[['heart_rate', 'respiratory_rate']])

plt.scatter(data_cleaned['heart_rate'], data_cleaned['respiratory_rate'], c=data_cleaned['Cluster'], cmap='viridis', marker='o', label='Clustered Data')
plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], marker='x', s=100, color='red', label='Cluster Centers')

plt.xlabel('heart_rate')
plt.ylabel('respiratory_rate')
plt.title('K-means Clustering of heart_rate vs respiratory_rate')
plt.show()

"""### **ROC Curve**"""

from sklearn.metrics import roc_curve, auc
import numpy as np
from sklearn.preprocessing import label_binarize
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, mean_squared_error,r2_score
from sklearn.tree import DecisionTreeRegressor
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder
from sklearn.ensemble import RandomForestRegressor

data = pd.read_csv('/content/treadmillData1.csv')
# Define the column mapping
column_mapping = {
    'Age(years)': 'Age',
    'Weight(kg)': 'Weight',
    'Height(cm)': 'Height',
    'Humidity(%)': 'Humidity',
    'Speed(km/h)': 'Speed',
    'HR(per min)': 'heart_rate',
    'RR(per minute)': 'respiratory_rate',
    'Sex (Female - 1)': 'gender',
    # Add more mappings as needed
}

# Rename the columns based on the mapping
data.rename(columns=column_mapping, inplace=True)
data = data.dropna()

names = ['Age','Weight','Height','Humidity','respiratory_rate','Speed']
features = data[names]
target = data['heart_rate']
X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)

# Initialize Decision Tree Regressor
dt_regressor = DecisionTreeRegressor(random_state=42)

# Fit the model to the training data
dt_regressor.fit(X_train, y_train)

# Make predictions on the testing set
y_pred = dt_regressor.predict(X_test)

# Convert true labels to one-hot encoded format
y_test_onehot = label_binarize(y_test, classes=np.unique(y_test))

# Convert predicted class labels to one-hot encoded format
y_pred_onehot = label_binarize(y_pred, classes=np.unique(y_test))

# Compute ROC curve and ROC area for each class
fpr = dict()
tpr = dict()
roc_auc = dict()

for i in range(len(np.unique(y_test))):
    fpr[i], tpr[i], _ = roc_curve(y_test_onehot[:, i], y_pred_onehot[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# Compute micro-average ROC curve and ROC area
fpr_micro, tpr_micro, _ = roc_curve(y_test_onehot.ravel(), y_pred_onehot.ravel())
roc_auc_micro = auc(fpr_micro, tpr_micro)

# Plot ROC curves for each class
plt.figure(figsize=(8, 6))
for i in range(len(np.unique(y_test))):
    plt.plot(fpr[i], tpr[i], label=f'Class {i} (AUC = {roc_auc[i]:.2f})')

# Plot micro-average ROC curve
plt.plot(fpr_micro, tpr_micro, label=f'Micro-average (AUC = {roc_auc_micro:.2f})', linestyle='--', color='black')

# Plot the random baseline
plt.plot([0, 1], [0, 1], 'k--', label='Random')

plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend(loc='lower right')
plt.show()

"""### **Ploting Distinct Ages with Average Heart rate on each age category**"""

from sklearn.metrics import roc_curve, auc
import numpy as np
from sklearn.preprocessing import label_binarize
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

data = pd.read_csv('/content/treadmillData1.csv')
# Define the column mapping
column_mapping = {
    'Age(years)': 'Age',
    'Weight(kg)': 'Weight',
    'Height(cm)': 'Height',
    'Humidity(%)': 'Humidity',
    'Speed(km/h)': 'Speed',
    'HR(per min)': 'heart_rate',
    'RR(per minute)': 'respiratory_rate',
    'Sex (Female - 1)': 'gender',
    # Add more mappings as needed
}

# Rename the columns based on the mapping
data.rename(columns=column_mapping, inplace=True)
data = data.dropna()

grouped_data = data.groupby('Age')['heart_rate'].mean().reset_index()
# Extract age and average heart rate from grouped data
ages = grouped_data['Age']
average_heart_rate = grouped_data['heart_rate']

# Plotting
plt.figure(figsize=(10, 6))
plt.bar(ages, average_heart_rate, color='skyblue')
plt.title('Average Heart Rate by Age')
plt.xlabel('Age')
plt.ylabel('Average Heart Rate')
plt.show()

"""### **Confusion Matrix**"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import matplotlib.pyplot as plt

df = pd.read_csv('/content/treadmillData1.csv')
# Replace the column names accordingly
df.rename(columns={
    'Age(years)': 'Age',
    'Weight(kg)': 'Weight',
    'Height(cm)': 'Height',
    'Humidity(%)': 'Humidity',
    'Speed(km/h)': 'Speed',
    'HR(per min)': 'HeartRate',
    'RR(per minute)': 'RespiratoryRate',
    'Sex (Female - 1) ': 'Gender'
}, inplace=True)
# Rename the columns based on the mapping
data.rename(columns=column_mapping, inplace=True)
# Drop rows with missing values
df.dropna(inplace=True)

# Define features (X) and target variable (y)
X = df.drop('Gender', axis=1)
y = df['Gender']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a classifier (Random Forest in this example)
clf = RandomForestClassifier(random_state=42)
clf.fit(X_train, y_train)

# Make predictions on the test set
y_pred = clf.predict(X_test)

# Create a confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)

# Plot the confusion matrix using seaborn
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Male', 'Female'], yticklabels=['Male', 'Female'])
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()

# Print classification report for additional metrics
print(classification_report(y_test, y_pred))
9